{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始权值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x,W,[1,1,1,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(x,is_train):\n",
    "    return tf.layers.batch_normalization(x,training=is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../public-dataset/MNIST_DATA\\train-images-idx3-ubyte.gz\n",
      "Extracting ../public-dataset/MNIST_DATA\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../public-dataset/MNIST_DATA\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../public-dataset/MNIST_DATA\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../public-dataset/MNIST_DATA',one_hot=True)\n",
    "global_step = tf.Variable(0,trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,[None,784]) #28x28\n",
    "y_ = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout 参数\n",
    "x_image= tf.reshape(x,[-1,28,28,1])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "x_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = 'CheckPointDir'  # 保存训练节点文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1 layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])  # patch 5x5, in size 1, out size 32\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)  # output size 28x28x32  28/1\n",
    "h_pool1 = max_pool_2x2(h_conv1)  # output size 14x14x32  28/2\n",
    "\n",
    "# conv2 layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])  # patch 5x5, in size 32, out size 64\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)  # output size 14x14x64\n",
    "h_pool2 = max_pool_2x2(h_conv2)  # output size 7x7x64\n",
    "\n",
    "# full connect layer 1\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "# [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# full connect layer 2\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_pre = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_,logits=y_pre))\n",
    "train_step = tf.train.AdadeltaOptimizer(1e-4).minimize(cross_entropy, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y_pre,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.train.Saver是用来保存训练结果的。\n",
    "# max_to_keep 用来设置最多保存多少个模型，默认是5\n",
    "# 如果保存的模型超过这个值，最旧的模型将被删除\n",
    "# 总的训练次数\n",
    "all_steps = 100000\n",
    "# 记录训练次数, 初始化为0\n",
    "step = 0\n",
    "# 每隔1000步保存模型\n",
    "save_interval = 1000\n",
    "saver = tf.train.Saver(max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "ckpt = tf.train.get_checkpoint_state(CKPT_DIR)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    # 读取网络中的global_step的值，即当前已经训练的次数\n",
    "    step = sess.run(global_step)\n",
    "    print('Cotinue from------')\n",
    "    print('------->Minibatch Step:',step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第11000步，当前loss：8.80\n",
      "第12000步，当前loss：7.81\n",
      "第13000步，当前loss：7.89\n",
      "第14000步，当前loss：7.31\n",
      "第15000步，当前loss：6.87\n",
      "第16000步，当前loss：6.86\n",
      "第17000步，当前loss：8.02\n",
      "第18000步，当前loss：7.66\n",
      "第19000步，当前loss：6.64\n",
      "第20000步，当前loss：6.00\n",
      "第21000步，当前loss：7.00\n",
      "第22000步，当前loss：6.29\n",
      "第23000步，当前loss：6.37\n",
      "第24000步，当前loss：6.96\n",
      "第25000步，当前loss：5.94\n",
      "第26000步，当前loss：6.40\n",
      "第27000步，当前loss：6.01\n",
      "第28000步，当前loss：6.70\n",
      "第29000步，当前loss：5.00\n",
      "第30000步，当前loss：5.97\n",
      "第31000步，当前loss：6.02\n",
      "第32000步，当前loss：5.86\n",
      "第33000步，当前loss：5.16\n",
      "第34000步，当前loss：6.21\n",
      "第35000步，当前loss：5.77\n",
      "第36000步，当前loss：5.88\n",
      "第37000步，当前loss：5.07\n",
      "第38000步，当前loss：5.68\n",
      "第39000步，当前loss：4.92\n",
      "第40000步，当前loss：4.84\n",
      "第41000步，当前loss：4.29\n",
      "第42000步，当前loss：4.49\n",
      "第43000步，当前loss：4.83\n",
      "第44000步，当前loss：4.14\n",
      "第45000步，当前loss：4.18\n",
      "第46000步，当前loss：4.84\n",
      "第47000步，当前loss：4.90\n",
      "第48000步，当前loss：3.79\n",
      "第49000步，当前loss：4.14\n",
      "第50000步，当前loss：4.48\n",
      "第51000步，当前loss：3.77\n",
      "第52000步，当前loss：3.42\n",
      "第53000步，当前loss：3.85\n",
      "第54000步，当前loss：4.11\n",
      "第55000步，当前loss：3.62\n",
      "第56000步，当前loss：3.55\n",
      "第57000步，当前loss：3.81\n",
      "第58000步，当前loss：4.16\n",
      "第59000步，当前loss：3.71\n",
      "第60000步，当前loss：3.09\n",
      "第61000步，当前loss：3.26\n",
      "第62000步，当前loss：3.82\n",
      "第63000步，当前loss：3.50\n",
      "第64000步，当前loss：3.24\n",
      "第65000步，当前loss：2.95\n",
      "第66000步，当前loss：2.80\n",
      "第67000步，当前loss：3.20\n",
      "第68000步，当前loss：3.29\n",
      "第69000步，当前loss：3.02\n",
      "第70000步，当前loss：2.90\n",
      "第71000步，当前loss：2.77\n",
      "第72000步，当前loss：2.73\n",
      "第73000步，当前loss：3.09\n",
      "第74000步，当前loss：3.22\n",
      "第75000步，当前loss：2.76\n",
      "第76000步，当前loss：2.68\n",
      "第77000步，当前loss：2.72\n",
      "第78000步，当前loss：2.90\n",
      "第79000步，当前loss：2.86\n",
      "第80000步，当前loss：2.38\n",
      "第81000步，当前loss：2.47\n",
      "第82000步，当前loss：2.33\n",
      "第83000步，当前loss：1.99\n",
      "第84000步，当前loss：2.52\n",
      "第85000步，当前loss：2.12\n",
      "第86000步，当前loss：2.16\n",
      "第87000步，当前loss：2.16\n",
      "第88000步，当前loss：2.38\n",
      "第89000步，当前loss：2.68\n",
      "第90000步，当前loss：2.41\n",
      "第91000步，当前loss：2.30\n",
      "第92000步，当前loss：1.85\n",
      "第93000步，当前loss：2.21\n",
      "第94000步，当前loss：2.24\n",
      "第95000步，当前loss：2.32\n",
      "第96000步，当前loss：2.19\n",
      "第97000步，当前loss：2.13\n",
      "第98000步，当前loss：1.97\n",
      "第99000步，当前loss：2.25\n",
      "第100000步，当前loss：2.27\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "while step<all_steps:\n",
    "    # 从数据集中获取 输入和标签(也就是答案)\n",
    "    x_train,y_train = mnist.train.next_batch(batch_size)\n",
    "    # loss只是为了看到损失的大小，方便打印\n",
    "    _,loss = sess.run([train_step,cross_entropy],feed_dict={\n",
    "        x:x_train,\n",
    "        y_:y_train,\n",
    "        keep_prob:0.5,\n",
    "    })\n",
    "    step = sess.run(global_step)\n",
    "    # 打印 loss，训练过程中将会看到，loss有变小的趋势\n",
    "    # 代表随着训练的进行，网络识别图像的能力提高\n",
    "    # 但是由于网络规模较小，后期没有明显下降，而是有明显波动\n",
    "    if step%1000==0:\n",
    "        print('第{0:5d}步，当前loss：{1:.2f}'.format(step, loss))\n",
    "    # 模型保存在ckpt文件夹下\n",
    "    # 模型文件名最后会增加global_step的值，比如1000的模型文件名为 model-1000\n",
    "    if step % save_interval == 0:\n",
    "        saver.save(sess, CKPT_DIR + '/model', global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument 0.222 has invalid type <class 'numpy.float32'>, must be a string or Tensor. (Can not convert a float32 into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\wang\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    281\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 282\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    283\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wang\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3338\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3339\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wang\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3427\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[1;32m-> 3428\u001b[1;33m                                                            types_str))\n\u001b[0m\u001b[0;32m   3429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a float32 into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-0049624ef527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m })\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"准确率: {0:.2f}，共测试了{1:d}张图片 \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wang\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wang\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1085\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wang\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \"\"\"\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wang\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[1;32mc:\\users\\wang\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    284\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    285\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    287\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument 0.222 has invalid type <class 'numpy.float32'>, must be a string or Tensor. (Can not convert a float32 into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "test_x,test_label = mnist.test.next_batch(500)\n",
    "accuracy = sess.run(accuracy, feed_dict={\n",
    "    x: test_x,\n",
    "    y_: test_label,\n",
    "    keep_prob:1,\n",
    "})\n",
    "print(\"准确率: {0:.2f}，共测试了{1:d}张图片 \".format(accuracy, len(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
